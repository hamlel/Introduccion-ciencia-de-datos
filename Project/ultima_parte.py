# -*- coding: utf-8 -*-
"""Ultima_parte.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11zFnXgbzk19zfI93iLpFnMVJGWWm9MK4
"""

# Instalación de dependencias
!pip install biopython scikit-learn seaborn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re, random, math
from Bio import SeqIO
from Bio.Seq import Seq
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             confusion_matrix, roc_curve, auc)

########################################
## 1. Definición del HMM y funciones auxiliares ##
########################################

# Mapeo de símbolos de aminoácidos (incluye '-' para gap)
mapping = {
    '-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7,
    'H': 8, 'I': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15,
    'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'V': 20, 'W': 21, 'X': 22, 'Y': 23, 'Z': 24
}

# Parámetros del HMM (3 estados, donde el estado 2 se asume como "maduro")
pi = np.array([9.19940546e-12, 1.78638610e-11, 2.93642133e-26])
A = np.array([
    [3.38220930e-25, 1.76381577e-24, 4.10395569e-37],
    [1.32807604e-24, 7.37423936e-25, 2.17001257e-37],
    [1.96093753e-26, 5.88554611e-25, 3.64816700e-32]
])
B = np.array([
    [0.07331865, 0.02064851, 0.12780465, 0.06690709, 0.03660996, 0.02248008,
     0.01966867, 0.03247551, 0.03405164, 0.03530193, 0.03714944, 0.0559964,
     0.01920217, 0.03278945, 0.00302967, 0.03782364, 0.06335918, 0.03334262,
     0.03994367, 0.05764876, 0.01778827, 0.06448174, 0.00986542, 0.00735919,
     0.0509537 ],
    [0.07201242, 0.03908993, 0.00256319, 0.0257781,  0.03575457, 0.02784481,
     0.01598341, 0.03046005, 0.02267819, 0.0632987,  0.0248095,  0.05506448,
     0.0181712,  0.02926533, 0.07980465, 0.02449131, 0.07987155, 0.04980082,
     0.06636549, 0.06037899, 0.02777204, 0.07089215, 0.01834305, 0.01801249,
     0.04149359],
    [0.01401651, 0.06388306, 0.01935875, 0.09896996, 0.02284183, 0.02032068,
     0.0295951,  0.01396067, 0.11017385, 0.00450196, 0.11435443, 0.06056661,
     0.0172307,  0.00036665, 0.00286863, 0.10921637, 0.05864509, 0.0578824,
     0.0067453,  0.02708583, 0.00948144, 0.02949,    0.09653353, 0.01141916,
     0.00049147]
])

def viterbi(obs, pi, A, B):
    """
    Implementa el algoritmo de Viterbi en logaritmos.
    obs: lista de índices (observaciones).
    Retorna:
      best_path: secuencia óptima de estados.
      best_score: log-probabilidad asociada.
    """
    N = len(obs)
    num_states = len(pi)
    T1 = np.full((num_states, N), -np.inf)
    T2 = np.zeros((num_states, N), dtype=int)
    epsilon = 1e-300
    for s in range(num_states):
        T1[s, 0] = np.log(pi[s] + epsilon) + np.log(B[s, obs[0]] + epsilon)
        T2[s, 0] = 0
    for t in range(1, N):
        for s in range(num_states):
            prob_vals = T1[:, t-1] + np.log(A[:, s] + epsilon) + np.log(B[s, obs[t]] + epsilon)
            T1[s, t] = np.max(prob_vals)
            T2[s, t] = np.argmax(prob_vals)
    best_path = np.zeros(N, dtype=int)
    best_path[-1] = np.argmax(T1[:, N-1])
    for t in range(N-2, -1, -1):
        best_path[t] = T2[best_path[t+1], t+1]
    best_score = np.max(T1[:, N-1])
    return best_path, best_score

def sequence_to_indices(seq, mapping):
    """Convierte una secuencia (string) a una lista de índices."""
    return [mapping.get(res, 0) for res in seq]

def extract_region_from_state(seq, state_seq, target_state=2):
    """
    Extrae la subsecuencia asociada al estado target_state.
    Retorna (subsecuencia, inicio, fin) o (None, None, None) si no se encuentra.
    """
    indices = [i for i, st in enumerate(state_seq) if st == target_state]
    if not indices:
        return None, None, None
    start = min(indices)
    end = max(indices) + 1
    return seq[start:end], start, end

def translate_transcript(transcript_seq):
    """
    Traduce una secuencia nucleotídica a proteína hasta el primer codón STOP.
    """
    seq_obj = Seq(transcript_seq)
    protein_seq = seq_obj.translate(to_stop=True)
    return str(protein_seq)

########################################
## 2. Evaluación en Entrenamiento (HMM + Extracción de Características)
########################################

training_filename = "prueba_secuencia_completa.txt"
print("Cargando archivo de entrenamiento:", training_filename)
records_train = list(SeqIO.parse(training_filename, "fasta"))
print("Total de registros en entrenamiento:", len(records_train))

# Generamos características para cada secuencia. Se asigna:
# label = 1 (maduro) si el header NO contiene "precursor", 0 en caso contrario.
training_data = []
training_labels = []
for rec in records_train:
    seq_str = str(rec.seq).strip().upper()
    if len(seq_str) == 0:
        print(f"Advertencia: El registro {rec.id} tiene secuencia vacía y se omitirá.")
        continue
    label = 1 if "precursor" not in rec.description.lower() else 0
    obs = sequence_to_indices(seq_str, mapping)
    if len(obs) == 0:
        print(f"Advertencia: La secuencia de {rec.id} no se convirtió a índices; se omitirá.")
        continue
    state_seq, score = viterbi(obs, pi, A, B)
    pred_region, pred_start, pred_end = extract_region_from_state(seq_str, state_seq, target_state=2)
    pred_length = (pred_end - pred_start) if pred_region is not None else 0
    ratio = pred_length / len(seq_str)
    training_data.append([len(seq_str), score, pred_length, ratio])
    training_labels.append(label)

df_features = pd.DataFrame(training_data, columns=["full_length", "viterbi_score", "pred_length", "ratio"])
df_features["label"] = training_labels
print("Características de entrenamiento (primeros 5 registros):")
display(df_features.head())

########################################
## 3. Entrenamiento y Evaluación del Clasificador SVM ##
########################################

X = df_features[["full_length", "viterbi_score", "pred_length", "ratio"]].values
y = df_features["label"].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Usamos kernel RBF; para la curva ROC usaremos un clasificador con probability=True
svm_clf = SVC(kernel="rbf", C=1.0, gamma="scale")
svm_clf.fit(X_train, y_train)

y_pred = svm_clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall_val = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)

print("Métricas del SVM en el conjunto de prueba:")
print("Accuracy:", acc)
print("Precisión:", prec)
print("Recall:", recall_val)
print("F1 Score:", f1)
print("Matriz de Confusión:\n", cm)

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicción")
plt.ylabel("Etiqueta Verdadera")
plt.title("Matriz de Confusión del SVM")
plt.show()

########################################
## 4. Predicción en Transcriptoma (HMM + SVM)
########################################

transcript_filename = "transcriptoma_dietas.txt"
print("Procesando transcriptoma:", transcript_filename)
transcript_records = list(SeqIO.parse(transcript_filename, "fasta"))

svm_transcript_predictions = []
for rec in transcript_records:
    transcript_seq = str(rec.seq).strip().upper()
    protein_seq = translate_transcript(transcript_seq)
    if len(protein_seq) < 30:
        continue
    obs = sequence_to_indices(protein_seq, mapping)
    if len(obs) == 0:
        continue
    state_seq, score = viterbi(obs, pi, A, B)
    pred_region, pred_start, pred_end = extract_region_from_state(protein_seq, state_seq, target_state=2)
    pred_length = (pred_end - pred_start) if pred_region is not None else 0
    ratio = pred_length / len(protein_seq)
    feature_vector = [len(protein_seq), score, pred_length, ratio]
    svm_class = svm_clf.predict([feature_vector])[0]
    svm_transcript_predictions.append({
        "id": rec.id,
        "protein_length": len(protein_seq),
        "viterbi_score": score,
        "pred_length": pred_length,
        "ratio": ratio,
        "svm_class": svm_class
    })

df_svm_trans = pd.DataFrame(svm_transcript_predictions)
print("Resultados SVM en el Transcriptoma (primeros registros):")
display(df_svm_trans.head())

# Gráfico final: Distribución de etiquetas SVM en el transcriptoma
counts = df_svm_trans["svm_class"].value_counts()
labels_dict = {0: "No maduro", 1: "Maduro"}
plt.figure(figsize=(6,6))
plt.pie(counts, labels=[labels_dict[k] for k in counts.index], autopct="%1.1f%%", startangle=90)
plt.title("Distribución de Predicciones del SVM en el Transcriptoma")
plt.show()

# Guardar resultados en archivos CSV
df_features.to_csv("resultados_entrenamiento_features.csv", index=False)
df_svm_trans.to_csv("resultados_svm_transcriptoma.csv", index=False)
print("Resultados guardados en 'resultados_entrenamiento_features.csv' y 'resultados_svm_transcriptoma.csv'.")

########################################
## 5. Gráficos Adicionales con Enfoque Bioinformático ##
########################################

# 5.1. Pairplot de las características según la etiqueta (maduro vs precursor)
sns.pairplot(df_features, hue="label", palette="Set1")
plt.suptitle("Pairplot de Características (Entrenamiento)", y=1.02)
plt.show()

# 5.2. Violin plots para comparar la distribución de cada característica según la etiqueta
plt.figure(figsize=(12,10))
for i, feature in enumerate(["full_length", "viterbi_score", "pred_length", "ratio"]):
    plt.subplot(2, 2, i+1)
    sns.violinplot(x="label", y=feature, data=df_features, palette="Set2")
    plt.title(f"Distribución de {feature} por Etiqueta")
    plt.xlabel("Etiqueta (0: Precursor, 1: Maduro)")
    plt.ylabel(feature)
plt.tight_layout()
plt.show()

# 5.3. Matriz de correlación entre características
corr = df_features[["full_length", "viterbi_score", "pred_length", "ratio"]].corr()
plt.figure(figsize=(8,6))
sns.heatmap(corr, annot=True, cmap="viridis")
plt.title("Matriz de Correlación entre Características")
plt.show()

# 5.4. Jointplot: Distribución conjunta de longitud total vs. longitud de región predicha
sns.jointplot(x="full_length", y="pred_length", data=df_features, kind="hex", cmap="mako")
plt.suptitle("Distribución conjunta: Longitud Total vs. Región Predicha", y=1.02)
plt.show()

# 5.5. Curva ROC para el SVM: entrenamos un modelo con probability=True para obtener probabilidades
svm_clf_prob = SVC(kernel="rbf", C=1.0, gamma="scale", probability=True, random_state=42)
svm_clf_prob.fit(X_train, y_train)
y_proba = svm_clf_prob.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label="ROC curve (AUC = %0.2f)" % roc_auc)
plt.plot([0, 1], [0, 1], "k--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Curva ROC del SVM")
plt.legend(loc="lower right")
plt.show()